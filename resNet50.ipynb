{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import tensorflow as tf\nfrom tensorflow.keras.preprocessing.image import ImageDataGenerator\nfrom tensorflow.keras.applications import ResNet50\nfrom tensorflow.keras.layers import GlobalAveragePooling2D, Dense, Flatten, Dropout\nfrom tensorflow.keras.optimizers import Adam\n\ndata_dir = '/kaggle/input/sisdata/laiba-20230810T045334Z-001/laiba'\n\ninput_shape = (224, 224)\nbatch_size = 24\n\ndatagen = ImageDataGenerator(\n    rescale=1.0/255,\n    validation_split=0.2\n)\n\ntrain_generator = datagen.flow_from_directory(\n    data_dir,\n    target_size=input_shape,\n    batch_size=batch_size,\n    class_mode='binary',\n    subset='training'\n)\n\nvalid_generator = datagen.flow_from_directory(\n    data_dir,\n    target_size=input_shape,\n    batch_size=batch_size,\n    class_mode='binary',\n    subset='validation'\n)\n\ndef build_model(learning_rate):\n    base_model = ResNet50(\n        include_top=False,\n        weights='imagenet',\n        input_shape=(224, 224, 3)\n    )\n\n    for layer in base_model.layers:\n        layer.trainable = False\n\n    x = base_model.output\n    x = Flatten()(x)\n    #x = GlobalAveragePooling2D()(x)\n    x = Dense(64, activation='relu')(x)\n    x = Dropout(0.2)(x)\n    x = Dense(32, activation='relu')(x)\n    predictions = Dense(1, activation='sigmoid')(x)\n\n    model = tf.keras.Model(inputs=base_model.input, outputs=predictions)\n\n    model.compile(optimizer=Adam(learning_rate=learning_rate), loss='binary_crossentropy', metrics=['accuracy'])\n\n    return model\n\n# Hyperparameters to tune\nlearning_rates = [5e-3, 8e-3, 1e-3, 3e-3]\n\nbest_loss = 1000\nbest_accuracy = 0.0\nbest_model = None\nbest_lr = 0\n\n# Iteration over different learning rates\nfor lr in learning_rates:\n    model = build_model(learning_rate=lr)\n    print(\"----------- For -------------\")\n    print(\"-----------\", lr,\"-------------\")\n    epochs = 20\n    model.fit(train_generator, epochs=epochs, validation_data=valid_generator, verbose=1)\n\n    loss, accuracy = model.evaluate(valid_generator)\n\n    if loss < best_loss:\n        best_lr = lr\n        best_loss = loss\n        best_accuracy = accuracy\n        best_model = model\n\nprint(\"Best Validation Accuracy:\", best_accuracy)\nprint(\"Best Validation Loss:\", best_loss)\n\n# Evaluate the best model\nvalidation_loss, validation_acc = best_model.evaluate(valid_generator)\nprint(\"Validation Loss:\", validation_loss)\nprint(\"Validation Accuracy:\", validation_acc)\nprint(\"Learning Rate:\", best_lr)\n","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2023-08-10T05:13:16.125051Z","iopub.execute_input":"2023-08-10T05:13:16.125405Z","iopub.status.idle":"2023-08-10T05:25:15.033851Z","shell.execute_reply.started":"2023-08-10T05:13:16.125375Z","shell.execute_reply":"2023-08-10T05:25:15.032737Z"},"trusted":true},"execution_count":1,"outputs":[{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/scipy/__init__.py:146: UserWarning: A NumPy version >=1.16.5 and <1.23.0 is required for this version of SciPy (detected version 1.23.5\n  warnings.warn(f\"A NumPy version >={np_minversion} and <{np_maxversion}\"\n/opt/conda/lib/python3.10/site-packages/tensorflow_io/python/ops/__init__.py:98: UserWarning: unable to load libtensorflow_io_plugins.so: unable to open file: libtensorflow_io_plugins.so, from paths: ['/opt/conda/lib/python3.10/site-packages/tensorflow_io/python/ops/libtensorflow_io_plugins.so']\ncaused by: ['/opt/conda/lib/python3.10/site-packages/tensorflow_io/python/ops/libtensorflow_io_plugins.so: undefined symbol: _ZN3tsl6StatusC1EN10tensorflow5error4CodeESt17basic_string_viewIcSt11char_traitsIcEENS_14SourceLocationE']\n  warnings.warn(f\"unable to load libtensorflow_io_plugins.so: {e}\")\n/opt/conda/lib/python3.10/site-packages/tensorflow_io/python/ops/__init__.py:104: UserWarning: file system plugins are not loaded: unable to open file: libtensorflow_io.so, from paths: ['/opt/conda/lib/python3.10/site-packages/tensorflow_io/python/ops/libtensorflow_io.so']\ncaused by: ['/opt/conda/lib/python3.10/site-packages/tensorflow_io/python/ops/libtensorflow_io.so: undefined symbol: _ZTVN10tensorflow13GcsFileSystemE']\n  warnings.warn(f\"file system plugins are not loaded: {e}\")\n","output_type":"stream"},{"name":"stdout","text":"Found 176 images belonging to 2 classes.\nFound 42 images belonging to 2 classes.\nDownloading data from https://storage.googleapis.com/tensorflow/keras-applications/resnet/resnet50_weights_tf_dim_ordering_tf_kernels_notop.h5\n94765736/94765736 [==============================] - 3s 0us/step\n----------- For -------------\n----------- 0.005 -------------\nEpoch 1/20\n8/8 [==============================] - 19s 1s/step - loss: 6.4182 - accuracy: 0.5852 - val_loss: 0.5964 - val_accuracy: 0.7381\nEpoch 2/20\n8/8 [==============================] - 8s 1s/step - loss: 4.0997 - accuracy: 0.4489 - val_loss: 1.2966 - val_accuracy: 0.5000\nEpoch 3/20\n8/8 [==============================] - 7s 834ms/step - loss: 2.4181 - accuracy: 0.5795 - val_loss: 0.2845 - val_accuracy: 0.8571\nEpoch 4/20\n8/8 [==============================] - 6s 857ms/step - loss: 1.6878 - accuracy: 0.5966 - val_loss: 0.2624 - val_accuracy: 0.9286\nEpoch 5/20\n8/8 [==============================] - 6s 822ms/step - loss: 1.7102 - accuracy: 0.5852 - val_loss: 0.2481 - val_accuracy: 0.9524\nEpoch 6/20\n8/8 [==============================] - 6s 777ms/step - loss: 0.6592 - accuracy: 0.7102 - val_loss: 0.3777 - val_accuracy: 0.9524\nEpoch 7/20\n8/8 [==============================] - 6s 792ms/step - loss: 0.5364 - accuracy: 0.7443 - val_loss: 0.3012 - val_accuracy: 0.9762\nEpoch 8/20\n8/8 [==============================] - 6s 825ms/step - loss: 0.3434 - accuracy: 0.9091 - val_loss: 0.2036 - val_accuracy: 0.9524\nEpoch 9/20\n8/8 [==============================] - 7s 867ms/step - loss: 0.3551 - accuracy: 0.8239 - val_loss: 0.2138 - val_accuracy: 0.9762\nEpoch 10/20\n8/8 [==============================] - 6s 757ms/step - loss: 0.3135 - accuracy: 0.8920 - val_loss: 0.2067 - val_accuracy: 0.9524\nEpoch 11/20\n8/8 [==============================] - 7s 796ms/step - loss: 0.2567 - accuracy: 0.9034 - val_loss: 0.1642 - val_accuracy: 0.9524\nEpoch 12/20\n8/8 [==============================] - 8s 899ms/step - loss: 0.2658 - accuracy: 0.8864 - val_loss: 0.2334 - val_accuracy: 0.9762\nEpoch 13/20\n8/8 [==============================] - 6s 793ms/step - loss: 0.2603 - accuracy: 0.8580 - val_loss: 0.2111 - val_accuracy: 0.9524\nEpoch 14/20\n8/8 [==============================] - 6s 770ms/step - loss: 0.2588 - accuracy: 0.8920 - val_loss: 0.1599 - val_accuracy: 0.9524\nEpoch 15/20\n8/8 [==============================] - 6s 783ms/step - loss: 0.2132 - accuracy: 0.8920 - val_loss: 0.1373 - val_accuracy: 0.9524\nEpoch 16/20\n8/8 [==============================] - 6s 756ms/step - loss: 0.2217 - accuracy: 0.8636 - val_loss: 0.1791 - val_accuracy: 0.9762\nEpoch 17/20\n8/8 [==============================] - 6s 728ms/step - loss: 0.1597 - accuracy: 0.9545 - val_loss: 0.1518 - val_accuracy: 0.9762\nEpoch 18/20\n8/8 [==============================] - 6s 725ms/step - loss: 0.2551 - accuracy: 0.9034 - val_loss: 0.1255 - val_accuracy: 0.9524\nEpoch 19/20\n8/8 [==============================] - 6s 767ms/step - loss: 0.2508 - accuracy: 0.9034 - val_loss: 0.1470 - val_accuracy: 0.9524\nEpoch 20/20\n8/8 [==============================] - 6s 859ms/step - loss: 0.1788 - accuracy: 0.8977 - val_loss: 0.1471 - val_accuracy: 0.9762\n2/2 [==============================] - 1s 179ms/step - loss: 0.1471 - accuracy: 0.9762\n----------- For -------------\n----------- 0.008 -------------\nEpoch 1/20\n8/8 [==============================] - 12s 814ms/step - loss: 10.1088 - accuracy: 0.5170 - val_loss: 5.1022 - val_accuracy: 0.5000\nEpoch 2/20\n8/8 [==============================] - 6s 720ms/step - loss: 2.9604 - accuracy: 0.6080 - val_loss: 1.8916 - val_accuracy: 0.5000\nEpoch 3/20\n8/8 [==============================] - 6s 861ms/step - loss: 1.2635 - accuracy: 0.6932 - val_loss: 0.2256 - val_accuracy: 0.9524\nEpoch 4/20\n8/8 [==============================] - 7s 808ms/step - loss: 0.7167 - accuracy: 0.8068 - val_loss: 0.2013 - val_accuracy: 0.9524\nEpoch 5/20\n8/8 [==============================] - 6s 686ms/step - loss: 0.3880 - accuracy: 0.8352 - val_loss: 0.1490 - val_accuracy: 0.9524\nEpoch 6/20\n8/8 [==============================] - 6s 767ms/step - loss: 0.3368 - accuracy: 0.8011 - val_loss: 0.1805 - val_accuracy: 0.9524\nEpoch 7/20\n8/8 [==============================] - 6s 878ms/step - loss: 0.2853 - accuracy: 0.8693 - val_loss: 0.1586 - val_accuracy: 0.9524\nEpoch 8/20\n8/8 [==============================] - 6s 820ms/step - loss: 0.3536 - accuracy: 0.8125 - val_loss: 0.2299 - val_accuracy: 0.9524\nEpoch 9/20\n8/8 [==============================] - 6s 732ms/step - loss: 0.2729 - accuracy: 0.8352 - val_loss: 0.1466 - val_accuracy: 0.9524\nEpoch 10/20\n8/8 [==============================] - 6s 727ms/step - loss: 0.2322 - accuracy: 0.8920 - val_loss: 0.1515 - val_accuracy: 0.9524\nEpoch 11/20\n8/8 [==============================] - 6s 757ms/step - loss: 0.1675 - accuracy: 0.9205 - val_loss: 0.1491 - val_accuracy: 0.9524\nEpoch 12/20\n8/8 [==============================] - 6s 802ms/step - loss: 0.2414 - accuracy: 0.8864 - val_loss: 0.1371 - val_accuracy: 0.9524\nEpoch 13/20\n8/8 [==============================] - 7s 800ms/step - loss: 0.1876 - accuracy: 0.8920 - val_loss: 0.1490 - val_accuracy: 0.9524\nEpoch 14/20\n8/8 [==============================] - 6s 814ms/step - loss: 0.1766 - accuracy: 0.9318 - val_loss: 0.1345 - val_accuracy: 0.9762\nEpoch 15/20\n8/8 [==============================] - 6s 808ms/step - loss: 0.1387 - accuracy: 0.9659 - val_loss: 0.1460 - val_accuracy: 0.9524\nEpoch 16/20\n8/8 [==============================] - 6s 699ms/step - loss: 0.1410 - accuracy: 0.9489 - val_loss: 0.1301 - val_accuracy: 0.9762\nEpoch 17/20\n8/8 [==============================] - 6s 665ms/step - loss: 0.1188 - accuracy: 0.9602 - val_loss: 0.1489 - val_accuracy: 0.9524\nEpoch 18/20\n8/8 [==============================] - 6s 847ms/step - loss: 0.4871 - accuracy: 0.8352 - val_loss: 0.3282 - val_accuracy: 0.9524\nEpoch 19/20\n8/8 [==============================] - 6s 730ms/step - loss: 0.4082 - accuracy: 0.8580 - val_loss: 0.3221 - val_accuracy: 0.9524\nEpoch 20/20\n8/8 [==============================] - 7s 850ms/step - loss: 0.4248 - accuracy: 0.8523 - val_loss: 0.2853 - val_accuracy: 0.9524\n2/2 [==============================] - 1s 150ms/step - loss: 0.2853 - accuracy: 0.9524\n----------- For -------------\n----------- 0.001 -------------\nEpoch 1/20\n8/8 [==============================] - 11s 846ms/step - loss: 1.4451 - accuracy: 0.5511 - val_loss: 1.1371 - val_accuracy: 0.5000\nEpoch 2/20\n8/8 [==============================] - 6s 695ms/step - loss: 0.8716 - accuracy: 0.5682 - val_loss: 0.8634 - val_accuracy: 0.5000\nEpoch 3/20\n8/8 [==============================] - 6s 810ms/step - loss: 1.0243 - accuracy: 0.5114 - val_loss: 0.6279 - val_accuracy: 0.5000\nEpoch 4/20\n8/8 [==============================] - 6s 800ms/step - loss: 0.6742 - accuracy: 0.6136 - val_loss: 0.6243 - val_accuracy: 0.5000\nEpoch 5/20\n8/8 [==============================] - 6s 818ms/step - loss: 0.5989 - accuracy: 0.6136 - val_loss: 0.5342 - val_accuracy: 0.8810\nEpoch 6/20\n8/8 [==============================] - 6s 814ms/step - loss: 0.5732 - accuracy: 0.7159 - val_loss: 0.4655 - val_accuracy: 0.9286\nEpoch 7/20\n8/8 [==============================] - 6s 849ms/step - loss: 0.4849 - accuracy: 0.7955 - val_loss: 0.4089 - val_accuracy: 0.9524\nEpoch 8/20\n8/8 [==============================] - 6s 844ms/step - loss: 0.4684 - accuracy: 0.8068 - val_loss: 0.3641 - val_accuracy: 0.9524\nEpoch 9/20\n8/8 [==============================] - 6s 762ms/step - loss: 0.4062 - accuracy: 0.8523 - val_loss: 0.3149 - val_accuracy: 0.9524\nEpoch 10/20\n8/8 [==============================] - 6s 779ms/step - loss: 0.3830 - accuracy: 0.8580 - val_loss: 0.2733 - val_accuracy: 0.9524\nEpoch 11/20\n8/8 [==============================] - 6s 793ms/step - loss: 0.3702 - accuracy: 0.8750 - val_loss: 0.2566 - val_accuracy: 0.9524\nEpoch 12/20\n8/8 [==============================] - 6s 834ms/step - loss: 0.3965 - accuracy: 0.8295 - val_loss: 0.2590 - val_accuracy: 0.9524\nEpoch 13/20\n8/8 [==============================] - 6s 769ms/step - loss: 0.3522 - accuracy: 0.8352 - val_loss: 0.2712 - val_accuracy: 0.9524\nEpoch 14/20\n8/8 [==============================] - 6s 718ms/step - loss: 0.3597 - accuracy: 0.8352 - val_loss: 0.2324 - val_accuracy: 0.9524\nEpoch 15/20\n8/8 [==============================] - 6s 749ms/step - loss: 0.3180 - accuracy: 0.8523 - val_loss: 0.2227 - val_accuracy: 0.9762\nEpoch 16/20\n8/8 [==============================] - 6s 767ms/step - loss: 0.3364 - accuracy: 0.8409 - val_loss: 0.2010 - val_accuracy: 0.9524\nEpoch 17/20\n8/8 [==============================] - 6s 715ms/step - loss: 0.2585 - accuracy: 0.8977 - val_loss: 0.1918 - val_accuracy: 0.9524\nEpoch 18/20\n8/8 [==============================] - 6s 752ms/step - loss: 0.2466 - accuracy: 0.8807 - val_loss: 0.1899 - val_accuracy: 0.9524\nEpoch 19/20\n8/8 [==============================] - 6s 766ms/step - loss: 0.2611 - accuracy: 0.8807 - val_loss: 0.1790 - val_accuracy: 0.9524\nEpoch 20/20\n8/8 [==============================] - 7s 807ms/step - loss: 0.2434 - accuracy: 0.8977 - val_loss: 0.1746 - val_accuracy: 0.9524\n2/2 [==============================] - 1s 182ms/step - loss: 0.1746 - accuracy: 0.9524\n----------- For -------------\n----------- 0.003 -------------\nEpoch 1/20\n8/8 [==============================] - 11s 943ms/step - loss: 2.5841 - accuracy: 0.5682 - val_loss: 0.7148 - val_accuracy: 0.5000\nEpoch 2/20\n8/8 [==============================] - 6s 729ms/step - loss: 0.6824 - accuracy: 0.7500 - val_loss: 0.3962 - val_accuracy: 0.8333\nEpoch 3/20\n8/8 [==============================] - 6s 876ms/step - loss: 0.3744 - accuracy: 0.8580 - val_loss: 0.2532 - val_accuracy: 0.9524\nEpoch 4/20\n8/8 [==============================] - 6s 713ms/step - loss: 0.3310 - accuracy: 0.8693 - val_loss: 0.1792 - val_accuracy: 0.9524\nEpoch 5/20\n8/8 [==============================] - 6s 758ms/step - loss: 0.3165 - accuracy: 0.8864 - val_loss: 0.1800 - val_accuracy: 0.9524\nEpoch 6/20\n8/8 [==============================] - 6s 713ms/step - loss: 0.2679 - accuracy: 0.9261 - val_loss: 0.1472 - val_accuracy: 0.9524\nEpoch 7/20\n8/8 [==============================] - 6s 682ms/step - loss: 0.3346 - accuracy: 0.8807 - val_loss: 0.1327 - val_accuracy: 0.9524\nEpoch 8/20\n8/8 [==============================] - 7s 807ms/step - loss: 0.2586 - accuracy: 0.8807 - val_loss: 0.1579 - val_accuracy: 0.9524\nEpoch 9/20\n8/8 [==============================] - 6s 675ms/step - loss: 0.3122 - accuracy: 0.8239 - val_loss: 0.2788 - val_accuracy: 0.9524\nEpoch 10/20\n8/8 [==============================] - 6s 839ms/step - loss: 0.2765 - accuracy: 0.8807 - val_loss: 0.1428 - val_accuracy: 0.9524\nEpoch 11/20\n8/8 [==============================] - 6s 728ms/step - loss: 0.1342 - accuracy: 0.9489 - val_loss: 0.1547 - val_accuracy: 0.9524\nEpoch 12/20\n8/8 [==============================] - 6s 754ms/step - loss: 0.1554 - accuracy: 0.9318 - val_loss: 0.1226 - val_accuracy: 0.9762\nEpoch 13/20\n8/8 [==============================] - 6s 710ms/step - loss: 0.1470 - accuracy: 0.9489 - val_loss: 0.1603 - val_accuracy: 0.9762\nEpoch 14/20\n8/8 [==============================] - 6s 752ms/step - loss: 0.1879 - accuracy: 0.9034 - val_loss: 0.1369 - val_accuracy: 0.9762\nEpoch 15/20\n8/8 [==============================] - 6s 733ms/step - loss: 0.1967 - accuracy: 0.8523 - val_loss: 0.1327 - val_accuracy: 0.9524\nEpoch 16/20\n8/8 [==============================] - 6s 700ms/step - loss: 0.1673 - accuracy: 0.9148 - val_loss: 0.1488 - val_accuracy: 0.9762\nEpoch 17/20\n8/8 [==============================] - 6s 794ms/step - loss: 0.2714 - accuracy: 0.8693 - val_loss: 0.1480 - val_accuracy: 0.9524\nEpoch 18/20\n8/8 [==============================] - 6s 724ms/step - loss: 0.2138 - accuracy: 0.9261 - val_loss: 0.2066 - val_accuracy: 0.9524\nEpoch 19/20\n8/8 [==============================] - 6s 782ms/step - loss: 0.1663 - accuracy: 0.9545 - val_loss: 0.1268 - val_accuracy: 0.9524\nEpoch 20/20\n8/8 [==============================] - 6s 710ms/step - loss: 0.2349 - accuracy: 0.8807 - val_loss: 0.2123 - val_accuracy: 0.9524\n2/2 [==============================] - 1s 176ms/step - loss: 0.2123 - accuracy: 0.9524\nBest Validation Accuracy: 0.976190447807312\nBest Validation Loss: 0.14710958302021027\n2/2 [==============================] - 1s 180ms/step - loss: 0.1471 - accuracy: 0.9762\nValidation Loss: 0.14710956811904907\nValidation Accuracy: 0.976190447807312\nLearning Rate: 0.005\n","output_type":"stream"}]},{"cell_type":"code","source":"model = build_model(best_lr)\nmodel.fit(train_generator, epochs=100, validation_data=valid_generator, verbose=1)","metadata":{"execution":{"iopub.status.busy":"2023-08-10T05:29:53.242321Z","iopub.execute_input":"2023-08-10T05:29:53.242695Z","iopub.status.idle":"2023-08-10T05:43:38.749460Z","shell.execute_reply.started":"2023-08-10T05:29:53.242665Z","shell.execute_reply":"2023-08-10T05:43:38.748491Z"},"trusted":true},"execution_count":2,"outputs":[{"name":"stdout","text":"Epoch 1/100\n8/8 [==============================] - 11s 877ms/step - loss: 10.2406 - accuracy: 0.4602 - val_loss: 0.7538 - val_accuracy: 0.5000\nEpoch 2/100\n8/8 [==============================] - 6s 738ms/step - loss: 0.9199 - accuracy: 0.5284 - val_loss: 0.6975 - val_accuracy: 0.5000\nEpoch 3/100\n8/8 [==============================] - 6s 747ms/step - loss: 0.9592 - accuracy: 0.5000 - val_loss: 0.7020 - val_accuracy: 0.5000\nEpoch 4/100\n8/8 [==============================] - 6s 855ms/step - loss: 0.8778 - accuracy: 0.4886 - val_loss: 0.7239 - val_accuracy: 0.5000\nEpoch 5/100\n8/8 [==============================] - 6s 757ms/step - loss: 0.7674 - accuracy: 0.4886 - val_loss: 0.7201 - val_accuracy: 0.5000\nEpoch 6/100\n8/8 [==============================] - 6s 784ms/step - loss: 0.7030 - accuracy: 0.5568 - val_loss: 0.7425 - val_accuracy: 0.5000\nEpoch 7/100\n8/8 [==============================] - 6s 718ms/step - loss: 0.7877 - accuracy: 0.4489 - val_loss: 0.6935 - val_accuracy: 0.5000\nEpoch 8/100\n8/8 [==============================] - 6s 720ms/step - loss: 0.7179 - accuracy: 0.5341 - val_loss: 0.7691 - val_accuracy: 0.5000\nEpoch 9/100\n8/8 [==============================] - 6s 740ms/step - loss: 0.8056 - accuracy: 0.5909 - val_loss: 0.7003 - val_accuracy: 0.5000\nEpoch 10/100\n8/8 [==============================] - 6s 732ms/step - loss: 0.9057 - accuracy: 0.4943 - val_loss: 0.6935 - val_accuracy: 0.5000\nEpoch 11/100\n8/8 [==============================] - 7s 957ms/step - loss: 0.8669 - accuracy: 0.5114 - val_loss: 0.8558 - val_accuracy: 0.5000\nEpoch 12/100\n8/8 [==============================] - 6s 771ms/step - loss: 0.7381 - accuracy: 0.5227 - val_loss: 0.7139 - val_accuracy: 0.5000\nEpoch 13/100\n8/8 [==============================] - 6s 762ms/step - loss: 0.7298 - accuracy: 0.4716 - val_loss: 0.6922 - val_accuracy: 0.5000\nEpoch 14/100\n8/8 [==============================] - 6s 776ms/step - loss: 0.6973 - accuracy: 0.5114 - val_loss: 0.7015 - val_accuracy: 0.5000\nEpoch 15/100\n8/8 [==============================] - 6s 815ms/step - loss: 0.7090 - accuracy: 0.4602 - val_loss: 0.6917 - val_accuracy: 0.5000\nEpoch 16/100\n8/8 [==============================] - 6s 692ms/step - loss: 0.6943 - accuracy: 0.5284 - val_loss: 0.6946 - val_accuracy: 0.5000\nEpoch 17/100\n8/8 [==============================] - 6s 757ms/step - loss: 0.6946 - accuracy: 0.5227 - val_loss: 0.6950 - val_accuracy: 0.5000\nEpoch 18/100\n8/8 [==============================] - 6s 696ms/step - loss: 0.6920 - accuracy: 0.5000 - val_loss: 0.6871 - val_accuracy: 0.5000\nEpoch 19/100\n8/8 [==============================] - 6s 768ms/step - loss: 0.6894 - accuracy: 0.5000 - val_loss: 0.6826 - val_accuracy: 0.5000\nEpoch 20/100\n8/8 [==============================] - 6s 824ms/step - loss: 0.6915 - accuracy: 0.5909 - val_loss: 0.6839 - val_accuracy: 0.5000\nEpoch 21/100\n8/8 [==============================] - 6s 750ms/step - loss: 0.6780 - accuracy: 0.7614 - val_loss: 0.6699 - val_accuracy: 0.9048\nEpoch 22/100\n8/8 [==============================] - 6s 729ms/step - loss: 0.6643 - accuracy: 0.6307 - val_loss: 0.6491 - val_accuracy: 0.5000\nEpoch 23/100\n8/8 [==============================] - 6s 793ms/step - loss: 0.6340 - accuracy: 0.6080 - val_loss: 0.6671 - val_accuracy: 0.7857\nEpoch 24/100\n8/8 [==============================] - 6s 709ms/step - loss: 0.6236 - accuracy: 0.7898 - val_loss: 0.5735 - val_accuracy: 0.5000\nEpoch 25/100\n8/8 [==============================] - 6s 701ms/step - loss: 0.5993 - accuracy: 0.6364 - val_loss: 0.5746 - val_accuracy: 0.9286\nEpoch 26/100\n8/8 [==============================] - 6s 776ms/step - loss: 0.5790 - accuracy: 0.6761 - val_loss: 0.4942 - val_accuracy: 0.9524\nEpoch 27/100\n8/8 [==============================] - 6s 777ms/step - loss: 0.5303 - accuracy: 0.8011 - val_loss: 0.4176 - val_accuracy: 0.9286\nEpoch 28/100\n8/8 [==============================] - 6s 805ms/step - loss: 0.5188 - accuracy: 0.7841 - val_loss: 0.3913 - val_accuracy: 0.9524\nEpoch 29/100\n8/8 [==============================] - 6s 722ms/step - loss: 0.4757 - accuracy: 0.8011 - val_loss: 0.4141 - val_accuracy: 0.9524\nEpoch 30/100\n8/8 [==============================] - 6s 822ms/step - loss: 0.4317 - accuracy: 0.8295 - val_loss: 0.3511 - val_accuracy: 0.9524\nEpoch 31/100\n8/8 [==============================] - 7s 898ms/step - loss: 0.4124 - accuracy: 0.8466 - val_loss: 0.3471 - val_accuracy: 0.9524\nEpoch 32/100\n8/8 [==============================] - 6s 763ms/step - loss: 0.3807 - accuracy: 0.8807 - val_loss: 0.3198 - val_accuracy: 0.9524\nEpoch 33/100\n8/8 [==============================] - 6s 761ms/step - loss: 0.3989 - accuracy: 0.8636 - val_loss: 0.3109 - val_accuracy: 0.9524\nEpoch 34/100\n8/8 [==============================] - 6s 826ms/step - loss: 0.3910 - accuracy: 0.8523 - val_loss: 0.2995 - val_accuracy: 0.9524\nEpoch 35/100\n8/8 [==============================] - 6s 721ms/step - loss: 0.3507 - accuracy: 0.8920 - val_loss: 0.3018 - val_accuracy: 0.9524\nEpoch 36/100\n8/8 [==============================] - 6s 714ms/step - loss: 0.3523 - accuracy: 0.8750 - val_loss: 0.2781 - val_accuracy: 0.9524\nEpoch 37/100\n8/8 [==============================] - 6s 703ms/step - loss: 0.3586 - accuracy: 0.8693 - val_loss: 0.2767 - val_accuracy: 0.9524\nEpoch 38/100\n8/8 [==============================] - 6s 723ms/step - loss: 0.3121 - accuracy: 0.9091 - val_loss: 0.2648 - val_accuracy: 0.9524\nEpoch 39/100\n8/8 [==============================] - 6s 696ms/step - loss: 0.3396 - accuracy: 0.8807 - val_loss: 0.2568 - val_accuracy: 0.9524\nEpoch 40/100\n8/8 [==============================] - 6s 769ms/step - loss: 0.3028 - accuracy: 0.9034 - val_loss: 0.2486 - val_accuracy: 0.9524\nEpoch 41/100\n8/8 [==============================] - 6s 708ms/step - loss: 0.2948 - accuracy: 0.9148 - val_loss: 0.2460 - val_accuracy: 0.9524\nEpoch 42/100\n8/8 [==============================] - 6s 669ms/step - loss: 0.3554 - accuracy: 0.8636 - val_loss: 0.2430 - val_accuracy: 0.9524\nEpoch 43/100\n8/8 [==============================] - 6s 795ms/step - loss: 0.3049 - accuracy: 0.8977 - val_loss: 0.2315 - val_accuracy: 0.9524\nEpoch 44/100\n8/8 [==============================] - 6s 787ms/step - loss: 0.3130 - accuracy: 0.8920 - val_loss: 0.2274 - val_accuracy: 0.9524\nEpoch 45/100\n8/8 [==============================] - 6s 723ms/step - loss: 0.2849 - accuracy: 0.9034 - val_loss: 0.2231 - val_accuracy: 0.9524\nEpoch 46/100\n8/8 [==============================] - 7s 875ms/step - loss: 0.3569 - accuracy: 0.8523 - val_loss: 0.2212 - val_accuracy: 0.9524\nEpoch 47/100\n8/8 [==============================] - 7s 830ms/step - loss: 0.2646 - accuracy: 0.9205 - val_loss: 0.2202 - val_accuracy: 0.9524\nEpoch 48/100\n8/8 [==============================] - 6s 734ms/step - loss: 0.2987 - accuracy: 0.8920 - val_loss: 0.2138 - val_accuracy: 0.9524\nEpoch 49/100\n8/8 [==============================] - 6s 704ms/step - loss: 0.2671 - accuracy: 0.9148 - val_loss: 0.2108 - val_accuracy: 0.9524\nEpoch 50/100\n8/8 [==============================] - 6s 705ms/step - loss: 0.3113 - accuracy: 0.8807 - val_loss: 0.2088 - val_accuracy: 0.9524\nEpoch 51/100\n8/8 [==============================] - 6s 712ms/step - loss: 0.2934 - accuracy: 0.8977 - val_loss: 0.2089 - val_accuracy: 0.9524\nEpoch 52/100\n8/8 [==============================] - 6s 782ms/step - loss: 0.2737 - accuracy: 0.9034 - val_loss: 0.2027 - val_accuracy: 0.9524\nEpoch 53/100\n8/8 [==============================] - 6s 748ms/step - loss: 0.3319 - accuracy: 0.8693 - val_loss: 0.2091 - val_accuracy: 0.9524\nEpoch 54/100\n8/8 [==============================] - 6s 789ms/step - loss: 0.2773 - accuracy: 0.9091 - val_loss: 0.1991 - val_accuracy: 0.9524\nEpoch 55/100\n8/8 [==============================] - 6s 700ms/step - loss: 0.2795 - accuracy: 0.9034 - val_loss: 0.2021 - val_accuracy: 0.9524\nEpoch 56/100\n8/8 [==============================] - 6s 853ms/step - loss: 0.2723 - accuracy: 0.9034 - val_loss: 0.1964 - val_accuracy: 0.9524\nEpoch 57/100\n8/8 [==============================] - 6s 804ms/step - loss: 0.2188 - accuracy: 0.9375 - val_loss: 0.1939 - val_accuracy: 0.9524\nEpoch 58/100\n8/8 [==============================] - 6s 783ms/step - loss: 0.2599 - accuracy: 0.9148 - val_loss: 0.1971 - val_accuracy: 0.9524\nEpoch 59/100\n8/8 [==============================] - 6s 764ms/step - loss: 0.2825 - accuracy: 0.9034 - val_loss: 0.2638 - val_accuracy: 0.9048\nEpoch 60/100\n8/8 [==============================] - 6s 747ms/step - loss: 0.2911 - accuracy: 0.8977 - val_loss: 0.3733 - val_accuracy: 0.8571\nEpoch 61/100\n8/8 [==============================] - 7s 971ms/step - loss: 0.2952 - accuracy: 0.8977 - val_loss: 0.1849 - val_accuracy: 0.9762\nEpoch 62/100\n8/8 [==============================] - 6s 743ms/step - loss: 0.2694 - accuracy: 0.9091 - val_loss: 0.1976 - val_accuracy: 0.9524\nEpoch 63/100\n8/8 [==============================] - 6s 727ms/step - loss: 0.2723 - accuracy: 0.9034 - val_loss: 0.1804 - val_accuracy: 0.9524\nEpoch 64/100\n8/8 [==============================] - 6s 742ms/step - loss: 0.3200 - accuracy: 0.8750 - val_loss: 0.1956 - val_accuracy: 0.9524\nEpoch 65/100\n8/8 [==============================] - 6s 794ms/step - loss: 0.2870 - accuracy: 0.8920 - val_loss: 0.1898 - val_accuracy: 0.9524\nEpoch 66/100\n8/8 [==============================] - 6s 659ms/step - loss: 0.2483 - accuracy: 0.9148 - val_loss: 0.1942 - val_accuracy: 0.9524\nEpoch 67/100\n8/8 [==============================] - 6s 729ms/step - loss: 0.3057 - accuracy: 0.8807 - val_loss: 0.1793 - val_accuracy: 0.9524\nEpoch 68/100\n8/8 [==============================] - 6s 765ms/step - loss: 0.2887 - accuracy: 0.8920 - val_loss: 0.1953 - val_accuracy: 0.9524\nEpoch 69/100\n8/8 [==============================] - 6s 693ms/step - loss: 0.3180 - accuracy: 0.8693 - val_loss: 0.1837 - val_accuracy: 0.9524\nEpoch 70/100\n8/8 [==============================] - 6s 722ms/step - loss: 0.2877 - accuracy: 0.8920 - val_loss: 0.1927 - val_accuracy: 0.9524\nEpoch 71/100\n8/8 [==============================] - 6s 714ms/step - loss: 0.3158 - accuracy: 0.8750 - val_loss: 0.1913 - val_accuracy: 0.9524\nEpoch 72/100\n8/8 [==============================] - 6s 748ms/step - loss: 0.2953 - accuracy: 0.8864 - val_loss: 0.1927 - val_accuracy: 0.9524\nEpoch 73/100\n8/8 [==============================] - 7s 852ms/step - loss: 0.2386 - accuracy: 0.9205 - val_loss: 0.1919 - val_accuracy: 0.9524\nEpoch 74/100\n8/8 [==============================] - 6s 704ms/step - loss: 0.2001 - accuracy: 0.9432 - val_loss: 0.1896 - val_accuracy: 0.9524\nEpoch 75/100\n8/8 [==============================] - 6s 690ms/step - loss: 0.2764 - accuracy: 0.8977 - val_loss: 0.1849 - val_accuracy: 0.9524\nEpoch 76/100\n8/8 [==============================] - 6s 747ms/step - loss: 0.2471 - accuracy: 0.9148 - val_loss: 0.1865 - val_accuracy: 0.9524\nEpoch 77/100\n8/8 [==============================] - 6s 795ms/step - loss: 0.3057 - accuracy: 0.8807 - val_loss: 0.1807 - val_accuracy: 0.9524\nEpoch 78/100\n8/8 [==============================] - 6s 770ms/step - loss: 0.2275 - accuracy: 0.9261 - val_loss: 0.1850 - val_accuracy: 0.9524\nEpoch 79/100\n8/8 [==============================] - 6s 798ms/step - loss: 0.2564 - accuracy: 0.9091 - val_loss: 0.1787 - val_accuracy: 0.9524\nEpoch 80/100\n8/8 [==============================] - 6s 731ms/step - loss: 0.2973 - accuracy: 0.8864 - val_loss: 0.1799 - val_accuracy: 0.9524\nEpoch 81/100\n8/8 [==============================] - 6s 779ms/step - loss: 0.2577 - accuracy: 0.9091 - val_loss: 0.1738 - val_accuracy: 0.9524\nEpoch 82/100\n8/8 [==============================] - 6s 754ms/step - loss: 0.2597 - accuracy: 0.9091 - val_loss: 0.1795 - val_accuracy: 0.9524\nEpoch 83/100\n8/8 [==============================] - 6s 725ms/step - loss: 0.2865 - accuracy: 0.8920 - val_loss: 0.1679 - val_accuracy: 0.9524\nEpoch 84/100\n8/8 [==============================] - 6s 801ms/step - loss: 0.2463 - accuracy: 0.9148 - val_loss: 0.1814 - val_accuracy: 0.9524\nEpoch 85/100\n8/8 [==============================] - 6s 752ms/step - loss: 0.3081 - accuracy: 0.8807 - val_loss: 0.1733 - val_accuracy: 0.9524\nEpoch 86/100\n8/8 [==============================] - 6s 733ms/step - loss: 0.3386 - accuracy: 0.8636 - val_loss: 0.1848 - val_accuracy: 0.9524\nEpoch 87/100\n8/8 [==============================] - 6s 738ms/step - loss: 0.3354 - accuracy: 0.8636 - val_loss: 0.1918 - val_accuracy: 0.9524\nEpoch 88/100\n8/8 [==============================] - 7s 827ms/step - loss: 0.2676 - accuracy: 0.9034 - val_loss: 0.1981 - val_accuracy: 0.9524\nEpoch 89/100\n8/8 [==============================] - 6s 735ms/step - loss: 0.2775 - accuracy: 0.8977 - val_loss: 0.1717 - val_accuracy: 0.9524\nEpoch 90/100\n8/8 [==============================] - 6s 720ms/step - loss: 0.2858 - accuracy: 0.8920 - val_loss: 0.1928 - val_accuracy: 0.9524\nEpoch 91/100\n8/8 [==============================] - 6s 756ms/step - loss: 0.2750 - accuracy: 0.8977 - val_loss: 0.1963 - val_accuracy: 0.9524\nEpoch 92/100\n8/8 [==============================] - 6s 805ms/step - loss: 0.2277 - accuracy: 0.9261 - val_loss: 0.1884 - val_accuracy: 0.9524\nEpoch 93/100\n8/8 [==============================] - 6s 708ms/step - loss: 0.2069 - accuracy: 0.9375 - val_loss: 0.1912 - val_accuracy: 0.9524\nEpoch 94/100\n8/8 [==============================] - 6s 704ms/step - loss: 0.3054 - accuracy: 0.8807 - val_loss: 0.1917 - val_accuracy: 0.9524\nEpoch 95/100\n8/8 [==============================] - 7s 802ms/step - loss: 0.2168 - accuracy: 0.9318 - val_loss: 0.1774 - val_accuracy: 0.9524\nEpoch 96/100\n8/8 [==============================] - 6s 749ms/step - loss: 0.3150 - accuracy: 0.8750 - val_loss: 0.1920 - val_accuracy: 0.9524\nEpoch 97/100\n8/8 [==============================] - 6s 729ms/step - loss: 0.3050 - accuracy: 0.8807 - val_loss: 0.1919 - val_accuracy: 0.9524\nEpoch 98/100\n8/8 [==============================] - 6s 649ms/step - loss: 0.2850 - accuracy: 0.8920 - val_loss: 0.1825 - val_accuracy: 0.9524\nEpoch 99/100\n8/8 [==============================] - 6s 753ms/step - loss: 0.2464 - accuracy: 0.9148 - val_loss: 0.1821 - val_accuracy: 0.9524\nEpoch 100/100\n8/8 [==============================] - 6s 800ms/step - loss: 0.2454 - accuracy: 0.9148 - val_loss: 0.1940 - val_accuracy: 0.9524\n","output_type":"stream"},{"execution_count":2,"output_type":"execute_result","data":{"text/plain":"<keras.callbacks.History at 0x78523c63bd00>"},"metadata":{}}]},{"cell_type":"code","source":"import numpy as np\nimport matplotlib.pyplot as plt\nfrom sklearn.metrics import classification_report, confusion_matrix\nimport seaborn as sns\n\n# # Load your trained model\n# model = best_model\n\n# Path to your testing data folder\ntest_data_dir = '/kaggle/input/sisdata/laiba_test'\n\n# Create a test data generator\ntest_datagen = ImageDataGenerator(rescale=1.0/255)\n\ntest_generator = test_datagen.flow_from_directory(\n    test_data_dir,\n    target_size=input_shape,\n    batch_size=1,  # Set batch size to 1 for one-by-one prediction\n    class_mode='binary',\n    shuffle=False  # Important: set shuffle to False for generating correct labels\n)\n\n# Make predictions on test data\npredictions = model.predict(test_generator)\n\n# Convert probabilities to class labels (0 or 1)\npredicted_labels = np.round(predictions).flatten()\n\n# Get true labels from the generator\ntrue_labels = test_generator.classes\n\n# Generate a classification report\nclass_labels = list(test_generator.class_indices.keys())\nclassification_rep = classification_report(true_labels, predicted_labels, target_names=class_labels)\n\nprint(\"Classification Report:\")\nprint(classification_rep)\n\n# Generate a confusion matrix\nconf_matrix = confusion_matrix(true_labels, predicted_labels)\nplt.figure(figsize=(8, 6))\nsns.heatmap(conf_matrix, annot=True, fmt=\"d\", cmap=\"Blues\", xticklabels=class_labels, yticklabels=class_labels)\nplt.xlabel(\"Predicted Labels\")\nplt.ylabel(\"True Labels\")\nplt.title(\"Confusion Matrix\")\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2023-08-10T05:58:38.011869Z","iopub.execute_input":"2023-08-10T05:58:38.012249Z","iopub.status.idle":"2023-08-10T05:58:40.981253Z","shell.execute_reply.started":"2023-08-10T05:58:38.012205Z","shell.execute_reply":"2023-08-10T05:58:40.980178Z"},"trusted":true},"execution_count":3,"outputs":[{"name":"stdout","text":"Found 28 images belonging to 2 classes.\n28/28 [==============================] - 2s 20ms/step\nClassification Report:\n              precision    recall  f1-score   support\n\n        real       1.00      0.83      0.91        12\n         sis       0.89      1.00      0.94        16\n\n    accuracy                           0.93        28\n   macro avg       0.94      0.92      0.93        28\nweighted avg       0.94      0.93      0.93        28\n\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<Figure size 800x600 with 2 Axes>","image/png":"iVBORw0KGgoAAAANSUhEUgAAAoAAAAIhCAYAAADejQtoAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjcuMiwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8pXeV/AAAACXBIWXMAAA9hAAAPYQGoP6dpAAA/d0lEQVR4nO3de5yN9f7//+eaMbPGaYYZDY0cZpxPOWeTw8hpTxJNhdhySoWKpmhLGjoY7JIiRM4p+hS2FJtCyinjVCHCMHax5ZRtMOZw/f7oZ333MoM1Y61Zq/V+3Pdt3T7W+7rWdb2W2+7Taz/f7+u9bJZlWQIAAIAxArxdAAAAAAoWDSAAAIBhaAABAAAMQwMIAABgGBpAAAAAw9AAAgAAGIYGEAAAwDA0gAAAAIahAQQAADAMDSDwJ/D999+rb9++io6OVkhIiIoVK6YGDRpowoQJOnPmjEfvvXPnTrVq1UphYWGy2WyaNGmS2+9hs9k0evRot1/3ZubOnSubzSabzab169fnOG5ZlipXriybzabY2Nh83WPq1KmaO3dunj6zfv3669YEAO5QyNsFALixmTNnatCgQapWrZqGDRummjVrKiMjQ8nJyZo+fbo2b96spUuXeuz+/fr1U1pamhYtWqSSJUuqYsWKbr/H5s2bdccdd7j9uq4qXry4Zs2alaPJ+/rrr3Xo0CEVL14839eeOnWqSpUqpT59+rj8mQYNGmjz5s2qWbNmvu8LADdCAwj4sM2bN2vgwIFq166dli1bJrvd7jjWrl07Pffcc1q1apVHa/jxxx81YMAAxcXFeewef/nLXzx2bVd069ZNCxcu1LvvvqvQ0FDH+KxZs9S0aVOdP3++QOrIyMiQzWZTaGio1/9OAPg3poABHzZ27FjZbDbNmDHDqfm7Kjg4WPfff7/jfXZ2tiZMmKDq1avLbrcrMjJSjz76qP797387fS42Nla1a9fWtm3b1KJFCxUpUkQxMTEaN26csrOzJf2/6dHMzExNmzbNMVUqSaNHj3b8+X9d/cyRI0ccY2vXrlVsbKwiIiJUuHBhlS9fXg8++KAuXrzoOCe3KeAff/xRnTt3VsmSJRUSEqJ69epp3rx5TudcnSr96KOPNHLkSEVFRSk0NFRt27bV/v37XftLlvTII49Ikj766CPH2O+//65PP/1U/fr1y/UzY8aMUZMmTRQeHq7Q0FA1aNBAs2bNkmVZjnMqVqyoPXv26Ouvv3b8/V1NUK/WvmDBAj333HMqW7as7Ha7Dh48mGMK+NSpUypXrpyaNWumjIwMx/X37t2rokWLqlevXi5/VwCQaAABn5WVlaW1a9eqYcOGKleunEufGThwoF544QW1a9dOy5cv16uvvqpVq1apWbNmOnXqlNO5J06cUM+ePfW3v/1Ny5cvV1xcnEaMGKEPPvhAktSxY0dt3rxZkvTQQw9p8+bNjveuOnLkiDp27Kjg4GDNnj1bq1at0rhx41S0aFFduXLlup/bv3+/mjVrpj179uidd97RkiVLVLNmTfXp00cTJkzIcf6LL76oo0eP6v3339eMGTP0888/q1OnTsrKynKpztDQUD300EOaPXu2Y+yjjz5SQECAunXrdt3v9sQTT+jjjz/WkiVLFB8fr6efflqvvvqq45ylS5cqJiZG9evXd/z9XTtdP2LECKWmpmr69On67LPPFBkZmeNepUqV0qJFi7Rt2za98MILkqSLFy/q4YcfVvny5TV9+nSXvicAOFgAfNKJEycsSVb37t1dOn/fvn2WJGvQoEFO41u3brUkWS+++KJjrFWrVpYka+vWrU7n1qxZ0+rQoYPTmCRr8ODBTmOJiYlWbv/vY86cOZYkKyUlxbIsy/rkk08sSdauXbtuWLskKzEx0fG+e/fult1ut1JTU53Oi4uLs4oUKWKdO3fOsizLWrdunSXJuvfee53O+/jjjy1J1ubNm29436v1btu2zXGtH3/80bIsy2rcuLHVp08fy7Isq1atWlarVq2ue52srCwrIyPDeuWVV6yIiAgrOzvbcex6n716v5YtW1732Lp165zGx48fb0myli5davXu3dsqXLiw9f3339/wOwJAbkgAAT+xbt06ScrxsMFdd92lGjVq6KuvvnIaL1OmjO666y6nsTvvvFNHjx51W0316tVTcHCwHn/8cc2bN0+HDx926XNr165VmzZtciSfffr00cWLF3Mkkf87DS798T0k5em7tGrVSpUqVdLs2bP1ww8/aNu2bded/r1aY9u2bRUWFqbAwEAFBQXp5Zdf1unTp3Xy5EmX7/vggw+6fO6wYcPUsWNHPfLII5o3b54mT56sOnXquPx5ALiKBhDwUaVKlVKRIkWUkpLi0vmnT5+WJN1+++05jkVFRTmOXxUREZHjPLvdrkuXLuWj2txVqlRJX375pSIjIzV48GBVqlRJlSpV0ttvv33Dz50+ffq63+Pq8f917Xe5ul4yL9/FZrOpb9+++uCDDzR9+nRVrVpVLVq0yPXc7777Tu3bt5f0x1PaGzdu1LZt2zRy5Mg83ze373mjGvv06aPLly+rTJkyrP0DkG80gICPCgwMVJs2bbR9+/YcD3Hk5moTdPz48RzHfv31V5UqVcpttYWEhEiS0tPTncavXWcoSS1atNBnn32m33//XVu2bFHTpk01dOhQLVq06LrXj4iIuO73kOTW7/K/+vTpo1OnTmn69Onq27fvdc9btGiRgoKCtGLFCnXt2lXNmjVTo0aN8nXP3B6muZ7jx49r8ODBqlevnk6fPq3nn38+X/cEABpAwIeNGDFClmVpwIABuT40kZGRoc8++0ySdM8990iS4yGOq7Zt26Z9+/apTZs2bqvr6pOs33//vdP41VpyExgYqCZNmujdd9+VJO3YseO657Zp00Zr1651NHxXzZ8/X0WKFPHYFilly5bVsGHD1KlTJ/Xu3fu659lsNhUqVEiBgYGOsUuXLmnBggU5znVXqpqVlaVHHnlENptNK1euVFJSkiZPnqwlS5bc8rUBmId9AAEf1rRpU02bNk2DBg1Sw4YNNXDgQNWqVUsZGRnauXOnZsyYodq1a6tTp06qVq2aHn/8cU2ePFkBAQGKi4vTkSNHNGrUKJUrV07PPvus2+q69957FR4erv79++uVV15RoUKFNHfuXB07dszpvOnTp2vt2rXq2LGjypcvr8uXLzuetG3btu11r5+YmKgVK1aodevWevnllxUeHq6FCxfq888/14QJExQWFua273KtcePG3fScjh07auLEierRo4cef/xxnT59Wm+88UauW/XUqVNHixYt0uLFixUTE6OQkJB8rdtLTEzUN998o9WrV6tMmTJ67rnn9PXXX6t///6qX7++oqOj83xNAOaiAQR83IABA3TXXXfprbfe0vjx43XixAkFBQWpatWq6tGjh5566inHudOmTVOlSpU0a9YsvfvuuwoLC9Nf//pXJSUl5brmL79CQ0O1atUqDR06VH/7299UokQJPfbYY4qLi9Njjz3mOK9evXpavXq1EhMTdeLECRUrVky1a9fW8uXLHWvoclOtWjVt2rRJL774ogYPHqxLly6pRo0amjNnTp5+UcNT7rnnHs2ePVvjx49Xp06dVLZsWQ0YMECRkZHq37+/07ljxozR8ePHNWDAAP33v/9VhQoVnPZJdMWaNWuUlJSkUaNGOSW5c+fOVf369dWtWzd9++23Cg4OdsfXA2AAm2X9z66lAAAA8HusAQQAADAMDSAAAIBhaAABAAAMQwMIAADgQzZs2KBOnTopKipKNptNy5Yty3HOvn37dP/99yssLEzFixfXX/7yF6Wmprp8DxpAAAAAH5KWlqa6detqypQpuR4/dOiQmjdvrurVq2v9+vXavXu3Ro0a5dik3xU8BQwAAOCjbDabli5dqi5dujjGunfvrqCgoFw3n3cVCSAAAIAHpaen6/z5806va39K01XZ2dn6/PPPVbVqVXXo0EGRkZFq0qRJrtPEN+KXG0Hf885mb5cAwENm9ajv7RIAeEh0KdenMN2tcP2nbn5SPr3QuZTGjBnjNJaYmKjRo0fn+VonT57UhQsXNG7cOL322msaP368Vq1apfj4eK1bt06tWrVy6Tp+2QACAAD4ihEjRighIcFpLLefjnRFdna2JKlz586On/isV6+eNm3apOnTp9MAAgAAuMzmuVVxdrs93w3ftUqVKqVChQqpZs2aTuM1atTQt99+6/J1aAABAABsNm9X4JLg4GA1btxY+/fvdxo/cOCAKlSo4PJ1aAABAAB8yIULF3Tw4EHH+5SUFO3atUvh4eEqX768hg0bpm7duqlly5Zq3bq1Vq1apc8++0zr1693+R40gAAAAB6cAs6r5ORktW7d2vH+6vrB3r17a+7cuXrggQc0ffp0JSUl6ZlnnlG1atX06aefqnnz5i7fgwYQAADAh8TGxupm2zT369dP/fr1y/c9aAABAAD+JGsA3cV38k4AAAAUCBJAAAAAH1oDWBDM+rYAAAAgAQQAADBtDSANIAAAAFPAAAAA8GckgAAAAIZNAZMAAgAAGIYEEAAAgDWAAAAA8GckgAAAAKwBBAAAgD8jAQQAADBsDSANIAAAAFPAAAAA8GckgAAAAIZNAZv1bQEAAEACCAAAQAIIAAAAv0YCCAAAEMBTwAAAAPBjJIAAAACGrQGkAQQAAGAjaAAAAPgzEkAAAADDpoDN+rYAAAAgAQQAAGANIAAAAPwaCSAAAABrAAEAAODPSAABAAAMWwNIAwgAAMAUMAAAAPwZCSAAAIBhU8AkgAAAAIYhAQQAAGANIAAAAPwZCSAAAABrAAEAAODPSAABAAAMWwNIAwgAAGBYA2jWtwUAAAAJIAAAAA+BAAAAwK+RAAIAALAGEAAAAP6MBhAAAMBm89wrjzZs2KBOnTopKipKNptNy5Ytu+65TzzxhGw2myZNmpSne9AAAgAA+JC0tDTVrVtXU6ZMueF5y5Yt09atWxUVFZXne7AGEAAAwINrANPT05Wenu40ZrfbZbfbcz0/Li5OcXFxN7zmL7/8oqeeekr/+te/1LFjxzzXRAIIAADgwSngpKQkhYWFOb2SkpLyXWp2drZ69eqlYcOGqVatWvm6BgkgAACAB40YMUIJCQlOY9dL/1wxfvx4FSpUSM8880y+r0EDCAAAjGfz4EbQN5ruzavt27fr7bff1o4dO26pZqaAAQAA/iS++eYbnTx5UuXLl1ehQoVUqFAhHT16VM8995wqVqzo8nVIAAEAgPE8mQC6U69evdS2bVunsQ4dOqhXr17q27evy9ehAQQAAPAhFy5c0MGDBx3vU1JStGvXLoWHh6t8+fKKiIhwOj8oKEhlypRRtWrVXL4HDSAAAIAPBYDJyclq3bq14/3VB0h69+6tuXPnuuUeNIAAAAA+JDY2VpZluXz+kSNH8nwPGkAAAGC8P8saQHehAQQAAMYzrQFkGxgAAADDkAACAADjkQACAADAr5EAAgAA45EAAgAAwK+RAAIAAJgVAJIAAgAAmIYEEAAAGI81gAAAAPBrJIAAAMB4piWANIAAAMB4pjWATAEDAAAYhgQQAAAYjwQQAAAAfo0EEAAAwKwAkAQQAADANCSAAADAeKwBBAAAgF8jAQQAAMYzLQGkAQQAAMYzrQFkChgAAMAwJIAAAABmBYAkgAAAAKYhAQQAAMZjDSAAAAD8GgkgAAAwHgkgAAAA/BoJIAAAMJ5pCSANIAAAMJ5pDSBTwAAAAIYhAQQAADArACQBBAAAMA0JIAAAMB5rAAEAAODXSAABAIDxSAABAADg10gAAQCA8UxLAGkAAQAAzOr/mAIGAAAwjdcSwO+//97lc++8804PVgIAAEzHFHABqVevnmw2myzLyvX41WM2m01ZWVkFXB0AAID/8loDmJKS4q1bAwAAOCEBLCAVKlTw1q0BAACM5lNPAe/du1epqam6cuWK0/j999/vpYrgK+6MKq5uDaNU5bZiKlUsWKNW/KSNh886ndO7yR3qWKu0iocU0r4T/9U761N05MwlL1UMIL8WzZ+ljV9/pX8fTVGw3a6adeqp38ChKlehordLgx8zLQH0iaeADx8+rLp166p27drq2LGjunTpoi5duuiBBx7QAw884O3y4ANCggJ16LeLmvx17ksHujeM0kP1b9fkr1M0cNH3OnMxQxO61FThIJ/4rziAPPhhV7I6xXfTWzMWKGnSe8rKytTIZ5/U5UsXvV0aUCA2bNigTp06KSoqSjabTcuWLXMcy8jI0AsvvKA6deqoaNGiioqK0qOPPqpff/01T/fwiX87DhkyRNHR0frPf/6jIkWKaM+ePdqwYYMaNWqk9evXe7s8+IDvjp7T7C3H9M2hM7kef7De7Vq47Rd9c+iMjpy5pPFrDiokKEBtqpUq4EoB3KrXJ05T+46dVTGmsmKqVFPCi6/o5H+O6+f9+7xdGvyYzWbz2Cuv0tLSVLduXU2ZMiXHsYsXL2rHjh0aNWqUduzYoSVLlujAgQN5ni31iSngzZs3a+3atbrtttsUEBCggIAANW/eXElJSXrmmWe0c+dOb5cIH3Z7qF0RRYOVnHrOMZaRZWn3L+dV6/biWvHjSe8VB+CWXUy7IEkqHhrq5Urg13xoBjguLk5xcXG5HgsLC9OaNWucxiZPnqy77rpLqampKl++vEv38IkGMCsrS8WKFZMklSpVSr/++quqVaumChUqaP/+/Tf8bHp6utLT053GsjOvKKBQsMfqhW8JLxIkSTp7McNp/OzFDJUubvdGSQDcxLIsvffOG6p1Z31VjKni7XKAfMmtV7Hb7bLb3fPvqN9//102m00lSpRw+TM+MQVcu3Ztx8bQTZo00YQJE7Rx40a98soriomJueFnk5KSFBYW5vQ6umZ+QZQNH3PtlpI2SbnvMgngz+LdiUlKOfSz/j5mvLdLgZ/z5BRwbr1KUlKSW+q+fPmy/v73v6tHjx4KzUNK7hMJ4EsvvaS0tDRJ0muvvab77rtPLVq0UEREhBYvXnzDz44YMUIJCQlOY/e/z5SxSc78/8lfeNEgx58lqUSRIJ29eOV6HwPg46ZOTNKWb9frjXdn67bI0t4uB8i33HoVd6R/GRkZ6t69u7KzszV16tQ8fdYnGsAOHTo4/hwTE6O9e/fqzJkzKlmy5E0XT+YWoTL9a5bj59N1Ou2KGpYroYO//fGUYKEAm+qWDdWMjUe9XB2AvLIsS1MnJmnThrWaMGWWykTd4e2SYABPbgPjzuneqzIyMtS1a1elpKRo7dq1eUr/JB9pAK86ePCgDh06pJYtWyo8PPy6PxMH84QEBahsWIjj/e2hIapUqoj+ezlTJy9c0ae7jqtn47L65dxl/fvcJfVsfIcuZ2Trq/2nvFg1gPx4982xWrdmpRLHTVLhIkV15vQf/xwXLVZMdnvITT4N+L+rzd/PP/+sdevWKSIiIs/X8IkG8PTp0+ratavWrVsnm82mn3/+WTExMXrsscdUokQJvfnmm94uEV5WLbKY3nqwluP9oJYVJUmr9p7UhC8PadH2X2UvFKAhraNV3F5I+/5zQcOX7dWljGwvVQwgv1Ys/ViSNPyp/k7jCS++ovYdO3ujJBjAl/aBvnDhgg4ePOh4n5KSol27dik8PFxRUVF66KGHtGPHDq1YsUJZWVk6ceKEJCk8PFzBwa7NgtosH4jZHn30UZ08eVLvv/++atSood27dysmJkarV6/Ws88+qz179uTpeve8s9lDlQLwtlk96nu7BAAeEl3Kewlv5edXeuzaB9/IfUuX61m/fr1at26dY7x3794aPXq0oqOjc/3cunXrFBsb69I9fCIBXL16tf71r3/pjjuc13lUqVJFR4+yhgsAAHiWL/0UXGxs7A2Xwbkju/OJBjAtLU1FihTJMX7q1Cm3L5oEAAC4lg/1fwXCJ/YBbNmypebP/39799lsNmVnZ+sf//hHrhEoAAAA8s8nEsA33nhDrVq1UnJysq5cuaLhw4drz549OnPmjDZu3Ojt8gAAgJ/zpSngguD1BDAjI0ODBg3S8uXLddddd6ldu3ZKS0tTfHy8du7cqUqVKnm7RAAAAL/i9QQwKChIP/74oyIiIjRmzBhvlwMAAAxkWADo/QRQ+mMbmFmzZnm7DAAAACN4PQGUpCtXruj999/XmjVr1KhRIxUtWtTp+MSJE71UGQAAMEFAgFkRoE80gD/++KMaNGggSTpw4IDTMdMWZQIAAHiaTzSA69at83YJAADAYKblTT7RAAIAAHiTaTOOPvEQCAAAAAoOCSAAADCeYQEgCSAAAIBpSAABAIDxWAMIAAAAv0YCCAAAjEcCCAAAAL9GAggAAIxnWABIAwgAAMAUMAAAAPwaCSAAADCeYQEgCSAAAIBpSAABAIDxWAMIAAAAv0YCCAAAjGdYAEgCCAAAYBoSQAAAYDzWAAIAAMCvkQACAADjGRYA0gACAAAwBQwAAAC/RgIIAACMZ1gASAIIAABgGhJAAABgPNYAAgAAwK+RAAIAAOMZFgCSAAIAAJiGBBAAABjPtDWANIAAAMB4hvV/TAEDAACYhgQQAAAYz7QpYBJAAAAAw5AAAgAA45EAAgAAwK+RAAIAAOMZFgCSAAIAAJiGBBAAABiPNYAAAACGsdk898qrDRs2qFOnToqKipLNZtOyZcucjluWpdGjRysqKkqFCxdWbGys9uzZk6d70AACAAD4kLS0NNWtW1dTpkzJ9fiECRM0ceJETZkyRdu2bVOZMmXUrl07/fe//3X5HkwBAwAA4/nSFHBcXJzi4uJyPWZZliZNmqSRI0cqPj5ekjRv3jyVLl1aH374oZ544gmX7kECCAAA4EHp6ek6f/680ys9PT1f10pJSdGJEyfUvn17x5jdblerVq20adMml69DAwgAAIznyTWASUlJCgsLc3olJSXlq84TJ05IkkqXLu00Xrp0accxVzAFDAAA4EEjRoxQQkKC05jdbr+la147ZW1ZVp6msWkAAQCA8QI8uAbQbrffcsN3VZkyZST9kQTefvvtjvGTJ0/mSAVvhClgAACAP4no6GiVKVNGa9ascYxduXJFX3/9tZo1a+bydUgAAQCA8XzoIWBduHBBBw8edLxPSUnRrl27FB4ervLly2vo0KEaO3asqlSpoipVqmjs2LEqUqSIevTo4fI9aAABAIDxfGkbmOTkZLVu3drx/ur6wd69e2vu3LkaPny4Ll26pEGDBuns2bNq0qSJVq9ereLFi7t8DxpAAAAAHxIbGyvLsq573GazafTo0Ro9enS+70EDCAAAjBfgOwFggeAhEAAAAMOQAAIAAOP50hrAgkACCAAAYBgSQAAAYDzDAkASQAAAANOQAAIAAOPZZFYESAMIAACMxzYwAAAA8GskgAAAwHhsAwMAAAC/RgIIAACMZ1gASAIIAABgGrckgOfOnVOJEiXccSkAAIACF2BYBJjnBHD8+PFavHix433Xrl0VERGhsmXLavfu3W4tDgAAAO6X5wbwvffeU7ly5SRJa9as0Zo1a7Ry5UrFxcVp2LBhbi8QAADA02w2z718UZ6ngI8fP+5oAFesWKGuXbuqffv2qlixopo0aeL2AgEAADyNbWBuomTJkjp27JgkadWqVWrbtq0kybIsZWVlubc6AAAAuF2eE8D4+Hj16NFDVapU0enTpxUXFydJ2rVrlypXruz2AgEAADzNsAAw7w3gW2+9pYoVK+rYsWOaMGGCihUrJumPqeFBgwa5vUAAAAC4V54bwKCgID3//PM5xocOHeqOegAAAAqcadvAuNQALl++3OUL3n///fkuBgAAAJ7nUgPYpUsXly5ms9l4EAQAAPzpmJX/udgAZmdne7oOAAAAFJBb+im4y5cvKyQkxF21AAAAeAX7AN5EVlaWXn31VZUtW1bFihXT4cOHJUmjRo3SrFmz3F4gAACApwXYPPfyRXluAF9//XXNnTtXEyZMUHBwsGO8Tp06ev/9991aHAAAANwvzw3g/PnzNWPGDPXs2VOBgYGO8TvvvFM//fSTW4sDAAAoCDabzWMvX5TnBvCXX37J9Rc/srOzlZGR4ZaiAAAA4Dl5bgBr1aqlb775Jsf4//3f/6l+/fpuKQoAAKAg2Wyee/miPD8FnJiYqF69eumXX35Rdna2lixZov3792v+/PlasWKFJ2oEAACAG+U5AezUqZMWL16sL774QjabTS+//LL27dunzz77TO3atfNEjQAAAB5l2hrAfO0D2KFDB3Xo0MHdtQAAAKAA5Hsj6OTkZO3bt082m001atRQw4YN3VkXAABAgfHV/fo8Jc8N4L///W898sgj2rhxo0qUKCFJOnfunJo1a6aPPvpI5cqVc3eNAAAAHuWrU7Wekuc1gP369VNGRob27dunM2fO6MyZM9q3b58sy1L//v09USMAAADcKM8J4DfffKNNmzapWrVqjrFq1app8uTJuvvuu91aHAAAQEEwK//LRwJYvnz5XDd8zszMVNmyZd1SFAAAADwnzw3ghAkT9PTTTys5OVmWZUn644GQIUOG6I033nB7gQAAAJ4WYLN57OWLXJoCLlmypNPiyLS0NDVp0kSFCv3x8czMTBUqVEj9+vVTly5dPFIoAAAA3MOlBnDSpEkeLgMAAMB7fDSo8xiXGsDevXt7ug4AAAAUkHxvBC1Jly5dyvFASGho6C0VBAAAUNDYB/Am0tLS9NRTTykyMlLFihVTyZIlnV4AAADwbXluAIcPH661a9dq6tSpstvtev/99zVmzBhFRUVp/vz5nqgRAADAo2w2z718UZ6ngD/77DPNnz9fsbGx6tevn1q0aKHKlSurQoUKWrhwoXr27OmJOgEAADzGV7dr8ZQ8J4BnzpxRdHS0pD/W+505c0aS1Lx5c23YsMG91QEAAMDt8twAxsTE6MiRI5KkmjVr6uOPP5b0RzJYokQJd9YGAABQIHxlCjgzM1MvvfSSoqOjVbhwYcXExOiVV15Rdna2W79vnqeA+/btq927d6tVq1YaMWKEOnbsqMmTJyszM1MTJ050a3EAAAAmGT9+vKZPn6558+apVq1aSk5OVt++fRUWFqYhQ4a47T55bgCfffZZx59bt26tn376ScnJyapUqZLq1q3rtsIAAAAKiq9sA7N582Z17txZHTt2lCRVrFhRH330kZKTk916nzxPAV+rfPnyio+PV3h4uPr16+eOmgAAAPxGenq6zp8/7/RKT0/P9dzmzZvrq6++0oEDByRJu3fv1rfffqt7773XrTXZLMuy3HGh3bt3q0GDBsrKynLH5W7J5UxvVwDAU0o2fsrbJQDwkEs7p3jt3k8v3eexa0fsXqwxY8Y4jSUmJmr06NE5zrUsSy+++KLGjx+vwMBAZWVl6fXXX9eIESPcWtMt/RIIAAAAbmzEiBFKSEhwGrPb7bmeu3jxYn3wwQf68MMPVatWLe3atUtDhw5VVFSUW3+alwYQAAAYz5NrAO12+3UbvmsNGzZMf//739W9e3dJUp06dXT06FElJSXRAAIAALhTgG88A6KLFy8qIMD5EY3AwEDvbQMTHx9/w+Pnzp271VoAAACM1qlTJ73++usqX768atWqpZ07d2rixIluf9DW5QYwLCzspscfffTRWy4IAACgoPlKAjh58mSNGjVKgwYN0smTJxUVFaUnnnhCL7/8slvv47angH0JTwED/oungAH/5c2ngBOW/+Sxa0+8v7rHrp1frAEEAADG85WNoAvKLW8EDQAAgD8XEkAAAGA8X1kDWFBIAAEAAAxDAggAAIxn2BLA/CWACxYs0N13362oqCgdPXpUkjRp0iT985//dGtxAAAABSHAZvPYyxfluQGcNm2aEhISdO+99+rcuXPKysqSJJUoUUKTJk1yd30AAABwszw3gJMnT9bMmTM1cuRIBQYGOsYbNWqkH374wa3FAQAAFIQAD758UZ7rSklJUf369XOM2+12paWluaUoAAAAeE6eG8Do6Gjt2rUrx/jKlStVs2ZNd9QEAABQoGw2z718UZ6fAh42bJgGDx6sy5cvy7Isfffdd/roo4+UlJSk999/3xM1AgAAwI3y3AD27dtXmZmZGj58uC5evKgePXqobNmyevvtt9W9e3dP1AgAAOBRvvq0rqfkax/AAQMGaMCAATp16pSys7MVGRnp7roAAADgIbe0EXSpUqXcVQcAAIDXGBYA5r0BjI6Olu0Gf0uHDx++pYIAAAAKmmm/BZznBnDo0KFO7zMyMrRz506tWrVKw4YNc1ddAAAA8JA8N4BDhgzJdfzdd99VcnLyLRcEAABQ0Ex7CMRtG1THxcXp008/ddflAAAA4CG39BDI//rkk08UHh7urssBAAAUGMMCwLw3gPXr13d6CMSyLJ04cUK//fabpk6d6tbiAAAA4H55bgC7dOni9D4gIEC33XabYmNjVb16dXfVBQAAUGB4CvgGMjMzVbFiRXXo0EFlypTxVE0AAADwoDw9BFKoUCENHDhQ6enpnqoHAACgwNk8+B9flOengJs0aaKdO3d6ohYAAACvCLB57uWL8rwGcNCgQXruuef073//Ww0bNlTRokWdjt95551uKw4AAADu53ID2K9fP02aNEndunWTJD3zzDOOYzabTZZlyWazKSsry/1VAgAAeJCvJnWe4nIDOG/ePI0bN04pKSmerAcAAAAe5nIDaFmWJKlChQoeKwYAAMAbbIbtBJ2nh0BM+8sBAADwR3l6CKRq1ao3bQLPnDlzSwUBAAAUNNYA3sCYMWMUFhbmqVoAAABQAPLUAHbv3l2RkZGeqgUAAMArTFvl5nIDyPo/AADgrwIM63Ncfgjk6lPAAAAA+HNzOQHMzs72ZB0AAABeY9pDIHn+LWAAAAD8ueX5t4ABAAD8jWFLAEkAAQAATEMCCAAAjBcgsyJAEkAAAADDkAACAADjmbYGkAYQAAAYj21gAAAA4NdIAAEAgPH4KTgAAAD4NRJAAABgPMMCQBJAAAAA09AAAgAA4wXYbB575dUvv/yiv/3tb4qIiFCRIkVUr149bd++3a3flylgAAAAH3H27Fndfffdat26tVauXKnIyEgdOnRIJUqUcOt9aAABAIDxPLkGMD09Xenp6U5jdrtddrs9x7njx49XuXLlNGfOHMdYxYoV3V4TU8AAAMB4AR58JSUlKSwszOmVlJSUax3Lly9Xo0aN9PDDDysyMlL169fXzJkz3f59bZZlWW6/qpddzvR2BQA8pWTjp7xdAgAPubRzitfuPXdbqseu/cidpV1OAENCQiRJCQkJevjhh/Xdd99p6NCheu+99/Too4+6rSamgAEAgPFsHpwDvl6zl5vs7Gw1atRIY8eOlSTVr19fe/bs0bRp09zaADIFDAAA4CNuv/121axZ02msRo0aSk11b0JJAggAAIznK/tA33333dq/f7/T2IEDB1ShQgW33ocEEAAAwEc8++yz2rJli8aOHauDBw/qww8/1IwZMzR48GC33ocEEAAAGC8/GzZ7QuPGjbV06VKNGDFCr7zyiqKjozVp0iT17NnTrfehAQQAAPAh9913n+677z6P3oMGEAAAGM838r+CQwMIAACM5yMzwAWGh0AAAAAMQwIIAACM58mNoH0RCSAAAIBhSAABAIDxTEvETPu+AAAAxiMBBAAAxmMNIAAAAPwaCSAAADCeWfkfCSAAAIBxSAABAIDxTFsDSAMIAACMZ9qUqGnfFwAAwHgkgAAAwHimTQGTAAIAABiGBBAAABjPrPyPBBAAAMA4JIAAAMB4hi0BJAEEAAAwDQkgAAAwXoBhqwBpAAEAgPGYAgYAAIBfIwEEAADGsxk2BUwCCAAAYBgSQAAAYDzWAAIAAMCvkQACAADjmbYNDAkgAACAYUgAAQCA8UxbA0gDCAAAjGdaA8gUMAAAgGFIAAEAgPHYCBoAAAB+jQQQAAAYL8CsAJAEEAAAwDQkgAAAwHisAQQAAIBfIwEEAADGM20fQBpAAABgPKaAAQAA4NdIAAEAgPHYBgYAAAB+jQQQAAAYjzWABezSpUu6ePGi4/3Ro0c1adIkrV692otVAQAA+C+vN4CdO3fW/PnzJUnnzp1TkyZN9Oabb6pz586aNm2al6uDr1v80ULFtb9HjevXUfeH47Vje7K3SwKQR3c3qKRPJj2hw6tf16WdU9Qp9s4c51SLLq3/m/SETmz4h05++4a+nvecypUp6YVq4a9sNs+9fJHXG8AdO3aoRYsWkqRPPvlEpUuX1tGjRzV//ny98847Xq4OvmzVyi80YVySBjw+UIs/WaYGDRpq0BMDdPzXX71dGoA8KFrYrh8O/KJnx32c6/HoO0rpq9kJOpByQh0GvK27uiUpaeYqXU7PKOBKgYKXlJQkm82moUOHuvW6Xl8DePHiRRUvXlyStHr1asXHxysgIEB/+ctfdPToUS9XB1+2YN4cPfDgg4p/6GFJ0vARI7Vp07f6ePFHGvLsc16uDoCrVm/cq9Ub9173+JinOulf3+7RyLf/6Rg78svpgigNBvHFoG7btm2aMWOG7rwzZyp+q7yeAFauXFnLli3TsWPH9K9//Uvt27eXJJ08eVKhoaFerg6+KuPKFe3bu0dNmzV3Gm/a7G7t3rXTS1UBcDebzaa/Nq+ln1NPavm7g3X0qyRtmP98rtPEwK0IsNk89sqPCxcuqGfPnpo5c6ZKlnT/cgevN4Avv/yynn/+eVWsWFFNmjRR06ZNJf2RBtavX/+mn09PT9f58+edXunp6Z4uG1529txZZWVlKSIiwmk8IqKUTp36zUtVAXC3yPBiKl40RM/3bac1m/aq08ApWr5utxa9+ZiaN6zs7fIAl+SnVxk8eLA6duyotm3beqQmrzeADz30kFJTU5WcnKxVq1Y5xtu0aaO33nrrpp9PSkpSWFiY0+sf45M8WTJ8iO2a/2VlWVaOMQB/XgEBf/xrasX6HzR54Tp9f+AXvTFnjb74Zo8GPNT8Jp8GXGfz4Cu3XiUp6fq9yqJFi7Rjx44bnnOrvL4GUJLKlCmjMmXKOI3dddddLn12xIgRSkhIcBqzAu1uqw2+qWSJkgoMDNSpU6ecxs+cOa2IiFJeqgqAu506e0EZGVnad/i40/j+wyfUrH6Ml6oC8ia3XsVuz71XOXbsmIYMGaLVq1crJCTEYzV5pQGMj4/X3LlzFRoaqvj4+Bueu2TJkhset9vtOf4SL2feconwcUHBwapRs5a2bNqoNm3bOca3bNqk2HvaeLEyAO6UkZml7XuPqmqF0k7jVSpEKvX4WS9VBb/kwcmj3HqV69m+fbtOnjyphg0bOsaysrK0YcMGTZkyRenp6QoMDLzlmrzSAIaFhTmm6cLCwrxRAvxAr959NfLvw1Wzdm3VrVtfn/7fYh0/flwPd+vu7dIA5EHRwsGqVO42x/uKZSN0Z9WyOnv+oo6dOKu35n2pBeP76dsdB/V18gG1b1ZT97asrQ4D3vZi1YBntGnTRj/88IPTWN++fVW9enW98MILbmn+JMlmWZbllivl06VLl5Sdna2iRYtKko4cOaJly5apRo0a6tChQ76uSQJojsUfLdTc2bP0228nVblKVQ17YYQaNmrs7bLgQSUbP+XtEuBmLRpW0er3h+QYX7B8ix5P/ECS9Gjnv2hYv/YqG1lCB46e1GvTP9eK9T/k+Az+3C7tnOK1e2899LvHrt2k0q2FXbGxsapXr54mTZrknoLkAw1g+/btFR8fryeffFLnzp1T9erVFRQUpFOnTmnixIkaOHBgnq9JAwj4LxpAwH/RAObOEw2g158C5pdAAACAt/nyT8GtX7/erc2f5ANPAfNLIAAAwNtM20DM6wkgvwQCAABQsLzeAN7qL4EAAADcMk/uBO2DvD4F/NBDD6l58+Y6fvy46tat6xhv06aNHnjgAS9WBgAA4J+83gBKt/ZLIAAAALfK5qtRnYd4fQoYAAAABcsnEkAAAABvcsd2LX8mJIAAAACGIQEEAADGMywApAEEAAAwrQNkChgAAMAwJIAAAMB4bAMDAAAAv0YCCAAAjMc2MAAAAPBrJIAAAMB4hgWAJIAAAACmIQEEAAAwLAKkAQQAAMZjGxgAAAD4NRJAAABgPLaBAQAAgF8jAQQAAMYzLAAkAQQAADANCSAAAIBhESAJIAAAgGFIAAEAgPHYBxAAAAB+jQQQAAAYz7R9AGkAAQCA8Qzr/5gCBgAAMA0JIAAAgGERIAkgAACAYUgAAQCA8dgGBgAAAH6NBBAAABjPtG1gSAABAAAMQwIIAACMZ1gASAMIAABgWgfIFDAAAIBhSAABAIDx2AYGAAAAfo0EEAAAGI9tYAAAAODXSAABAIDxDAsASQABAABMQwIIAABgWARIAggAAIxn8+B/8iIpKUmNGzdW8eLFFRkZqS5dumj//v1u/740gAAAAD7i66+/1uDBg7VlyxatWbNGmZmZat++vdLS0tx6H6aAAQCA8XxlG5hVq1Y5vZ8zZ44iIyO1fft2tWzZ0m33oQEEAADwoPT0dKWnpzuN2e122e32m372999/lySFh4e7tSamgAEAgPFsHnwlJSUpLCzM6ZWUlHTTmizLUkJCgpo3b67atWu78+vKZlmW5dYr+oDLmd6uAICnlGz8lLdLAOAhl3ZO8dq9j5y67LFr317clq8EcPDgwfr888/17bff6o477nBrTUwBAwAAeHANoKvTvf/r6aef1vLly7Vhwwa3N38SDSAAAIDPsCxLTz/9tJYuXar169crOjraI/ehAQQAAMbL6359njJ48GB9+OGH+uc//6nixYvrxIkTkqSwsDAVLlzYbfdhDSCAPxXWAAL+y5trAFPPpN/8pHwqH+769K/tOvvRzJkzR3369HFTRSSAAAAAPqOgcjkaQAAAYDzfmAAuOOwDCAAAYBgSQAAAYDxf+Sm4gkICCAAAYBgSQAAAAMNWAZIAAgAAGIYEEAAAGM+0NYA0gAAAwHiG9X9MAQMAAJiGBBAAABjPtClgEkAAAADDkAACAADj2QxbBUgCCAAAYBgSQAAAALMCQBJAAAAA05AAAgAA4xkWANIAAgAAsA0MAAAA/BoJIAAAMB7bwAAAAMCvkQACAACYFQCSAAIAAJiGBBAAABjPsACQBBAAAMA0JIAAAMB4pu0DSAMIAACMxzYwAAAA8GskgAAAwHimTQGTAAIAABiGBhAAAMAwNIAAAACGYQ0gAAAwHmsAAQAA4NdIAAEAgPFM2weQBhAAABiPKWAAAAD4NRJAAABgPMMCQBJAAAAA05AAAgAAGBYBkgACAAAYhgQQAAAYz7RtYEgAAQAADEMCCAAAjMc+gAAAAPBrJIAAAMB4hgWANIAAAACmdYBMAQMAABiGBhAAABjP5sH/5MfUqVMVHR2tkJAQNWzYUN98841bvy8NIAAAgA9ZvHixhg4dqpEjR2rnzp1q0aKF4uLilJqa6rZ72CzLstx2NR9xOdPbFQDwlJKNn/J2CQA85NLOKV67tyd7h5A8PnHRpEkTNWjQQNOmTXOM1ahRQ126dFFSUpJbaiIBBAAA8KD09HSdP3/e6ZWenp7ruVeuXNH27dvVvn17p/H27dtr06ZNbqvJL58CzmunjT+v9PR0JSUlacSIEbLb7d4uBwXAmwkBChb/fKMgebJ3GP1aksaMGeM0lpiYqNGjR+c499SpU8rKylLp0qWdxkuXLq0TJ064rSa/nAKGOc6fP6+wsDD9/vvvCg0N9XY5ANyIf77hL9LT03Mkfna7Pdf/YfPrr7+qbNmy2rRpk5o2beoYf/3117VgwQL99NNPbqmJrAwAAMCDrtfs5aZUqVIKDAzMkfadPHkyRyp4K1gDCAAA4COCg4PVsGFDrVmzxml8zZo1atasmdvuQwIIAADgQxISEtSrVy81atRITZs21YwZM5Samqonn3zSbfegAcSfmt1uV2JiIgvEAT/EP98wVbdu3XT69Gm98sorOn78uGrXrq0vvvhCFSpUcNs9eAgEAADAMKwBBAAAMAwNIAAAgGFoAAEAAAxDAwgjHDlyRDabTbt27fJ2KQBc1KdPH3Xp0sXbZQB+iaeAAQA+6e233xbPKQKeQQMIn3flyhUFBwd7uwwABSwsLMzbJQB+iylg+JzY2Fg99dRTSkhIUKlSpdSuXTvt3btX9957r4oVK6bSpUurV69eOnXqlOMzq1atUvPmzVWiRAlFRETovvvu06FDh7z4LQC46pNPPlGdOnVUuHBhRUREqG3btkpLS8sxBXy98wDkHQ0gfNK8efNUqFAhbdy4UePGjVOrVq1Ur149JScna9WqVfrPf/6jrl27Os5PS0tTQkKCtm3bpq+++koBAQF64IEHlJ2d7cVvAeBmjh8/rkceeUT9+vXTvn37tH79esXHx+eY+nX1PACuYQoYPqly5cqaMGGCJOnll19WgwYNNHbsWMfx2bNnq1y5cjpw4ICqVq2qBx980Onzs2bNUmRkpPbu3avatWsXaO0AXHf8+HFlZmYqPj7e8SsHderUyfd5AFxDAgif1KhRI8eft2/frnXr1qlYsWKOV/Xq1SXJMc176NAh9ejRQzExMQoNDVV0dLQkKTU1teCLB+CyunXrqk2bNqpTp44efvhhzZw5U2fPns33eQBcQwMIn1S0aFHHn7Ozs9WpUyft2rXL6fXzzz+rZcuWkqROnTrp9OnTmjlzprZu3aqtW7dK+uMBEgC+KzAwUGvWrNHKlStVs2ZNTZ48WdWqVVNKSkq+zgPgGhpA+LwGDRpoz549qlixoipXruz0Klq0qE6fPq19+/bppZdeUps2bVSjRg2SAeBPxGaz6e6779aYMWO0c+dOBQcHa+nSpfk+D8DN0QDC5w0ePFhnzpzRI488ou+++06HDx/W6tWr1a9fP2VlZalkyZKKiIjQjBkzdPDgQa1du1YJCQneLhuAC7Zu3aqxY8cqOTlZqampWrJkiX777TfVqFEjX+cBcA0NIHxeVFSUNm7cqKysLHXo0EG1a9fWkCFDFBYWpoCAAAUEBGjRokXavn27ateurWeffVb/+Mc/vF02ABeEhoZqw4YNuvfee1W1alW99NJLevPNNxUXF5ev8wC4xmbxDD0AAIBRSAABAAAMQwMIAABgGBpAAAAAw9AAAgAAGIYGEAAAwDA0gAAAAIahAQQAADAMDSAAAIBhaAAB5Nvo0aNVr149x/s+ffqoS5cuBV7HkSNHZLPZtGvXLo/d49rvmh8FUScAuIIGEPAzffr0kc1mk81mU1BQkGJiYvT8888rLS3N4/d+++23NXfuXJfOLehmKDY2VkOHDi2QewGAryvk7QIAuN9f//pXzZkzRxkZGfrmm2/02GOPKS0tTdOmTctxbkZGhoKCgtxy37CwMLdcBwDgWSSAgB+y2+0qU6aMypUrpx49eqhnz55atmyZpP83lTl79mzFxMTIbrfLsiz9/vvvevzxxxUZGanQ0FDdc8892r17t9N1x40bp9KlS6t48eLq37+/Ll++7HT82ing7OxsjR8/XpUrV5bdblf58uX1+uuvS5Kio6MlSfXr15fNZlNsbKzjc3PmzFGNGjUUEhKi6tWra+rUqU73+e6771S/fn2FhISoUaNG2rlz5y3/nb3wwguqWrWqihQpopiYGI0aNUoZGRk5znvvvfdUrlw5FSlSRA8//LDOnTvndPxmtf+vs2fPqmfPnrrttttUuHBhValSRXPmzLnl7wIAN0MCCBigcOHCTs3MwYMH9fHHH+vTTz9VYGCgJKljx44KDw/XF198obCwML333ntq06aNDhw4oPDwcH388cdKTEzUu+++qxYtWmjBggV65513FBMTc937jhgxQjNnztRbb72l5s2b6/jx4/rpp58k/dHE3XXXXfryyy9Vq1YtBQcHS5JmzpypxMRETZkyRfXr19fOnTs1YMAAFS1aVL1791ZaWpruu+8+3XPPPfrggw+UkpKiIUOG3PLfUfHixTV37lxFRUXphx9+0IABA1S8eHENHz48x9/bZ599pvPnz6t///4aPHiwFi5c6FLt1xo1apT27t2rlStXqlSpUjp48KAuXbp0y98FAG7KAuBXevfubXXu3NnxfuvWrVZERITVtWtXy7IsKzEx0QoKCrJOnjzpOOerr76yQkNDrcuXLztdq1KlStZ7771nWZZlNW3a1HryySedjjdp0sSqW7durvc+f/68ZbfbrZkzZ+ZaZ0pKiiXJ2rlzp9N4uXLlrA8//NBp7NVXX7WaNm1qWZZlvffee1Z4eLiVlpbmOD5t2rRcr/W/WrVqZQ0ZMuS6x681YcIEq2HDho73iYmJVmBgoHXs2DHH2MqVK62AgADr+PHjLtV+7Xfu1KmT1bdvX5drAgB3IQEE/NCKFStUrFgxZWZmKiMjQ507d9bkyZMdxytUqKDbbrvN8X779u26cOGCIiIinK5z6dIlHTp0SJK0b98+Pfnkk07HmzZtqnXr1uVaw759+5Senq42bdq4XPdvv/2mY8eOqX///howYIBjPDMz07G+cN++fapbt66KFCniVMet+uSTTzRp0iQdPHhQFy5cUGZmpkJDQ53OKV++vO644w6n+2ZnZ2v//v0KDAy8ae3XGjhwoB588EHt2LFD7du3V5cuXdSsWbNb/i4AcDM0gIAfat26taZNm6agoCBFRUXleMijaNGiTu+zs7N1++23a/369TmuVaJEiXzVULhw4Tx/Jjs7W9IfU6lNmjRxOnZ1qtqyrHzVcyNbtmxR9+7dNWbMGHXo0EFhYWFatGiR3nzzzRt+zmazOf6vK7VfKy4uTkePHtXnn3+uL7/8Um3atNHgwYP1xhtvuOFbAcD10QACfqho0aKqXLmyy+c3aNBAJ06cUKFChVSxYsVcz6lRo4a2bNmiRx991DG2ZcuW616zSpUqKly4sL766is99thjOY5fXfOXlZXlGCtdurTKli2rw4cPq2fPnrlet2bNmlqwYIEuXbrkaDJvVIcrNm7cqAoVKmjkyJGOsaNHj+Y4LzU1Vb/++quioqIkSZs3b1ZAQICqVq3qUu25ue2229SnTx/16dNHLVq00LBhw2gAAXgcDSAAtW3bVk2bNlWXLl00fvx4VatWTb/++qu++OILdenSRY0aNdKQIUPUu3dvNWrUSM2bN9fChQu1Z8+e6z4EEhISohdeeEHDhw9XcHCw7r77bv3222/as2eP+vfvr8jISBUuXFirVq3SHXfcoZCQEIWFhWn06NF65plnFBoaqri4OKWnpys5OVlnz55VQkKCevTooZEjR6p///566aWXdOTIEZcbpt9++y3HvoNlypRR5cqVlZqaqkWLFqlx48b6/PPPtXTp0ly/U+/evfXGG2/o/PnzeuaZZ9S1a1eVKVNGkm5a+7VefvllNWzYULVq1VJ6erpWrFihGjVquPRdAOCWeHsRIgD3uvYhkGslJiY6Pbhx1fnz562nn37aioqKsoKCgqxy5cpZPXv2tFJTUx3nvP7661apUqWsYsWKWb1797aGDx9+3YdALMuysrKyrNdee82qUKGCFRQUZJUvX94aO3as4/jMmTOtcuXKWQEBAVarVq0c4wsXLrTq1atnBQcHWyVLlrRatmxpLVmyxHF88+bNVt26da3g4GCrXr161qeffurSQyCScrwSExMty7KsYcOGWREREVaxYsWsbt26WW+99ZYVFhaW4+9t6tSpVlRUlBUSEmLFx8dbZ86ccbrPjWq/9iGQV1991apRo4ZVuHBhKzw83OrcubN1+PDh634HAHAXm2V5YEENAAAAfBYbQQMAABiGBhAAAMAwNIAAAACGoQEEAAAwDA0gAACAYWgAAQAADEMDCAAAYBgaQAAAAMPQAAIAABiGBhAAAMAwNIAAAACG+f8ACHJdySu7BoIAAAAASUVORK5CYII="},"metadata":{}}]},{"cell_type":"code","source":"model.save('/kaggle/working/resNet50.h5')","metadata":{"execution":{"iopub.status.busy":"2023-08-10T06:03:27.238986Z","iopub.execute_input":"2023-08-10T06:03:27.239390Z","iopub.status.idle":"2023-08-10T06:03:27.801972Z","shell.execute_reply.started":"2023-08-10T06:03:27.239360Z","shell.execute_reply":"2023-08-10T06:03:27.800923Z"},"trusted":true},"execution_count":4,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import os\nimport numpy as np\nimport matplotlib.pyplot as plt\nfrom sklearn.metrics import classification_report, confusion_matrix\nimport seaborn as sns\nfrom tensorflow.keras.models import load_model\nimport tensorflow as tf\nfrom tensorflow.keras.preprocessing.image import ImageDataGenerator\nfrom tensorflow.keras.applications import ResNet50\nfrom tensorflow.keras.layers import GlobalAveragePooling2D, Dense, Flatten, Dropout\nfrom tensorflow.keras.optimizers import Adam\n\n# Load your trained model\nmodel = load_model('/kaggle/input/resnet50/resNet50.h5')  # Replace with the actual path\n\n# Path to your testing data folder\ntest_data_dir = '/kaggle/input/sisdata/laiba_test'\n\n# Create a test data generator\ntest_datagen = ImageDataGenerator(rescale=1.0/255)\n\ntest_generator = test_datagen.flow_from_directory(\n    test_data_dir,\n    target_size=(224, 224),\n    batch_size=1,  # Set batch size to 1 for one-by-one prediction\n    class_mode='binary',\n    shuffle=False  # Important: set shuffle to False for generating correct labels\n)\n\n# Make predictions on test data\npredictions = model.predict(test_generator)\n\n# Convert probabilities to class labels (0 or 1)\npredicted_labels = np.round(predictions).flatten()\n\n# Get filenames from the generator\nfilenames = test_generator.filenames\n\n# Get true labels from the generator\ntrue_labels = test_generator.classes\n\n# Iterate through images, filenames, true labels, and predicted labels\nfor filename, true_label, predicted_label in zip(filenames, true_labels, predicted_labels):\n    img_path = os.path.join(test_data_dir, filename)\n    img = plt.imread(img_path)\n\n    predicted_class = \"Screen\" if predicted_label == 1 else \"Real\"\n    true_class = \"Screen\" if true_label == 1 else \"Real\"\n\n    plt.imshow(img)\n    plt.title(f\"True: {true_class}, Predicted: {predicted_class}\")\n    plt.axis('off')\n    plt.show()","metadata":{"trusted":true},"execution_count":null,"outputs":[]}]}